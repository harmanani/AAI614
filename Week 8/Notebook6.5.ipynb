{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# AAI614: Data Science & its Applications\n",
    "\n",
    "*Notebook 6.5: PCA for visualization*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/harmanani/AAI614/blob/main/Week%206/Notebook6.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "*Source: This notebook contains amended excerpts from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example I: Hand-written digits\n",
    "\n",
    "The usefulness of the dimensionality reduction may not be entirely apparent in only two dimensions, but becomes much more clear when looking at high-dimensional data.\n",
    "To see this, let's take a quick look at the application of PCA to the digits data.\n",
    "\n",
    "We start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data consists of 8×8 pixel images, meaning that they are 64-dimensional.\n",
    "To gain some intuition into the relationships between these points, we can use PCA to project them to a more manageable number of dimensions, say two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can now plot the first two principal components of each point to learn about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.colormaps.get_cmap('Spectral'))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall what these components mean: the full data is a 64-dimensional point cloud, and these points are the projection of each data point along the directions with the largest variance.\n",
    "Essentially, we have found the optimal stretch and rotation in 64-dimensional space that allows us to see the layout of the digits in two dimensions, and have done this in an unsupervised manner—that is, without reference to the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### What do the components mean?\n",
    "\n",
    "We can go a bit further here, and begin to ask what the reduced dimensions *mean*.\n",
    "This meaning can be understood in terms of combinations of basis vectors.\n",
    "For example, each image in the training set is defined by a collection of 64 pixel values, which we will call the vector $x$:\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, x_3 \\cdots x_{64}]\n",
    "$$\n",
    "\n",
    "One way we can think about this is in terms of a pixel basis.\n",
    "That is, to construct the image, we multiply each element of the vector by the pixel it describes, and then add the results together to build the image:\n",
    "\n",
    "$$\n",
    "{\\rm image}(x) = x_1 \\cdot{\\rm (pixel~1)} + x_2 \\cdot{\\rm (pixel~2)} + x_3 \\cdot{\\rm (pixel~3)} \\cdots x_{64} \\cdot{\\rm (pixel~64)}\n",
    "$$\n",
    "\n",
    "One way we might imagine reducing the dimension of this data is to zero out all but a few of these basis vectors.\n",
    "For example, if we use only the first eight pixels, we get an eight-dimensional projection of the data, but it is not very reflective of the whole image: we've thrown out nearly 90% of the pixels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "But the pixel-wise representation is not the only choice of basis. We can also use other basis functions, which each contain some pre-defined contribution from each pixel, and write something like\n",
    "\n",
    "$$\n",
    "image(x) = {\\rm mean} + x_1 \\cdot{\\rm (basis~1)} + x_2 \\cdot{\\rm (basis~2)} + x_3 \\cdot{\\rm (basis~3)} \\cdots\n",
    "$$\n",
    "\n",
    "PCA can be thought of as a process of choosing optimal basis functions, such that adding together just the first few of them is enough to suitably reconstruct the bulk of the elements in the dataset.\n",
    "The principal components, which act as the low-dimensional representation of our data, are simply the coefficients that multiply each of the elements in this series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Unlike the pixel basis, the PCA basis allows us to recover the salient features of the input image with just a mean plus eight components!\n",
    "The amount of each pixel in each component is the corollary of the orientation of the vector in our two-dimensional example.\n",
    "This is the sense in which PCA provides a low-dimensional representation of the data: it discovers a set of basis functions that are more efficient than the native pixel-basis of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choosing the number of components\n",
    "\n",
    "A vital part of using PCA in practice is the ability to estimate how many components are needed to describe the data.\n",
    "This can be determined by looking at the cumulative *explained variance ratio* as a function of the number of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA().fit(digits.data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This curve quantifies how much of the total, 64-dimensional variance is contained within the first $N$ components.\n",
    "For example, we see that with the digits the first 10 components contain approximately 75% of the variance, while you need around 50 components to describe close to 100% of the variance.\n",
    "\n",
    "Here we see that our two-dimensional projection loses a lot of information (as measured by the explained variance) and that we'd need about 20 components to retain 90% of the variance.  Looking at this plot for a high-dimensional dataset can help you understand the level of redundancy present in multiple observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example II: PCA as Noise Filtering\n",
    "\n",
    "PCA can also be used as a filtering approach for noisy data.\n",
    "The idea is this: any components with variance much larger than the effect of the noise should be relatively unaffected by the noise.\n",
    "So if you reconstruct the data using just the largest subset of principal components, you should be preferentially keeping the signal and throwing out the noise.\n",
    "\n",
    "Let's see how this looks with the digits data.\n",
    "First we will plot several of the input noise-free data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets add some random noise to create a noisy dataset, and re-plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy = np.random.normal(digits.data, 4)\n",
    "plot_digits(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's clear by eye that the images are noisy, and contain spurious pixels.\n",
    "Let's train a PCA on the noisy data, requesting that the projection preserve 50% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(0.50).fit(noisy)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here 50% of the variance amounts to 12 principal components.\n",
    "Now we compute these components, and then use the inverse of the transform to reconstruct the filtered digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "components = pca.transform(noisy)\n",
    "filtered = pca.inverse_transform(components)\n",
    "plot_digits(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This signal preserving/noise filtering property makes PCA a very useful feature selection routine—for example, rather than training a classifier on very high-dimensional data, you might instead train the classifier on the lower-dimensional representation, which will automatically serve to filter out random noise in the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example III: Eigenfaces\n",
    "\n",
    "Earlier we explored an example of using a PCA projection as a feature selector for facial recognition with a support vector machine.\n",
    "Here we will take a look back and explore a bit more of what went into that.\n",
    "Recall that we were using the Labeled Faces in the Wild dataset made available through Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look at the principal axes that span this dataset.\n",
    "Because this is a large dataset, we will use ``RandomizedPCA``—it contains a randomized method to approximate the first $N$ principal components much more quickly than the standard ``PCA`` estimator, and thus is very useful for high-dimensional data (here, a dimensionality of nearly 3,000).\n",
    "We will take a look at the first 150 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "pca = RandomizedPCA(150)\n",
    "pca.fit(faces.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this case, it can be interesting to visualize the images associated with the first several principal components (these components are technically known as \"eigenvectors,\"\n",
    "so these types of images are often called \"eigenfaces\").\n",
    "As you can see in this figure, they are as creepy as they sound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The results are very interesting, and give us insight into how the images vary: for example, the first few eigenfaces (from the top left) seem to be associated with the angle of lighting on the face, and later principal vectors seem to be picking out certain features, such as eyes, noses, and lips.\n",
    "Let's take a look at the cumulative variance of these components to see how much of the data information the projection is preserving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We see that these 150 components account for just over 90% of the variance.\n",
    "That would lead us to believe that using these 150 components, we would recover most of the essential characteristics of the data.\n",
    "To make this more concrete, we can compare the input images with the images reconstructed from these 150 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the components and projected faces\n",
    "pca = RandomizedPCA(150).fit(faces.data)\n",
    "components = pca.transform(faces.data)\n",
    "projected = pca.inverse_transform(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('150-dim\\nreconstruction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The top row here shows the input images, while the bottom row shows the reconstruction of the images from just 150 of the ~3,000 initial features.\n",
    "This visualization makes clear why the PCA feature selection is successful: although it reduces the dimensionality of the data by nearly a factor of 20, the projected images contain enough information that we might, by eye, recognize the individuals in the image.\n",
    "What this means is that our classification algorithm needs to be trained on 150-dimensional data rather than 3,000-dimensional data, which depending on the particular algorithm we choose, can lead to a much more efficient classification."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
